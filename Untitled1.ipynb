{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "#创建30个文件夹\n",
    "def mkdir(path):  # 判断是否存在指定文件夹，不存在则创建\n",
    "    # 引入模块\n",
    "    import os\n",
    "\n",
    "    # 去除首位空格\n",
    "    path = path.strip()\n",
    "    # 去除尾部 \\ 符号\n",
    "    path = path.rstrip(\"\\\\\")\n",
    "\n",
    "    # 判断路径是否存在\n",
    "    # 存在     True\n",
    "    # 不存在   False\n",
    "    isExists = os.path.exists(path)\n",
    "\n",
    "    # 判断结果\n",
    "    if not isExists:\n",
    "        # 如果不存在则创建目录\n",
    "        # 创建目录操作函数\n",
    "        os.makedirs(path)\n",
    "        return True\n",
    "    else:\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def preprocess_image(cv2im, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "\n",
    "    Args:\n",
    "        PIL_img (PIL_img): Image to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (Pytorch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    # Resize image\n",
    "    if resize_im:\n",
    "        cv2im = cv2.resize(cv2im, (224, 224))\n",
    "    im_as_arr = np.float32(cv2im)\n",
    "    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\n",
    "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(im_as_arr):\n",
    "        im_as_arr[channel] /= 255\n",
    "        im_as_arr[channel] -= mean[channel]\n",
    "        im_as_arr[channel] /= std[channel]\n",
    "    # Convert to float tensor\n",
    "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
    "    im_as_ten.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
    "    return im_as_var\n",
    "\n",
    "\n",
    "class FeatureVisualization():\n",
    "    def __init__(self,img_path,selected_layer):\n",
    "        self.img_path=img_path\n",
    "        self.selected_layer=selected_layer\n",
    "        self.pretrained_model = models.vgg16(pretrained=True).features\n",
    "        #print( self.pretrained_model)\n",
    "    def process_image(self):\n",
    "        img=cv2.imread(self.img_path)\n",
    "        img=preprocess_image(img)\n",
    "        return img\n",
    "\n",
    "    def get_feature(self):\n",
    "        # input = Variable(torch.randn(1, 3, 224, 224))\n",
    "        input=self.process_image()\n",
    "        print(\"input shape\",input.shape)\n",
    "        x=input\n",
    "        for index,layer in enumerate(self.pretrained_model):\n",
    "            #print(index)\n",
    "            #print(layer)\n",
    "            x=layer(x)\n",
    "            if (index == self.selected_layer):\n",
    "                return x\n",
    "\n",
    "    def get_single_feature(self):\n",
    "        features=self.get_feature()\n",
    "        print(\"features.shape\",features.shape)\n",
    "        feature=features[:,0,:,:]\n",
    "        print(feature.shape)\n",
    "        feature=feature.view(feature.shape[1],feature.shape[2])\n",
    "        print(feature.shape)\n",
    "        return features\n",
    "\n",
    "    def save_feature_to_img(self):\n",
    "        #to numpy\n",
    "        features=self.get_single_feature()\n",
    "        for i in range(features.shape[1]):\n",
    "            feature = features[:, i, :, :]\n",
    "            feature = feature.view(feature.shape[1], feature.shape[2])\n",
    "            feature = feature.data.numpy()\n",
    "            # use sigmod to [0,1]\n",
    "            feature = 1.0 / (1 + np.exp(-1 * feature))\n",
    "            # to [0,255]\n",
    "            feature = np.round(feature * 255)\n",
    "            print(feature[0])\n",
    "            mkdir('./feature/' + str(self.selected_layer))\n",
    "            cv2.imwrite('./feature/'+ str( self.selected_layer)+'/' +str(i)+'.jpg', feature)\n",
    "if __name__=='__main__':\n",
    "    # get class\n",
    "    for  k in range(30):\n",
    "        myClass=FeatureVisualization('/home/lqy/examples/TRP.PNG',k)\n",
    "        print (myClass.pretrained_model)\n",
    "        myClass.save_feature_to_img()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
